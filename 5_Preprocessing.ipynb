{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\Howlw\\anaconda3\\envs\\py3_TF2\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os, glob, re, scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg16_ppi\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input as vgg19_ppi\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input as Res50V2_ppi\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as inceptv3_ppi\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as moblv2_ppi\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input as inceptres_ppi\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input as xcept_ppi\n",
    "\n",
    "PRETRAINED_MODELS = {\n",
    "    'VGG16': {\n",
    "        'model': VGG16,\n",
    "        'preprocess': vgg16_ppi,\n",
    "        'shape': (224, 224)\n",
    "    },\n",
    "    'VGG19': {\n",
    "        'model': VGG19,\n",
    "        'preprocess': vgg19_ppi,\n",
    "        'shape': (224, 224)\n",
    "    },\n",
    "    'ResNet50V2': {\n",
    "        'model': ResNet50V2,\n",
    "        'preprocess': Res50V2_ppi,\n",
    "        'shape': (224, 224)\n",
    "    },\n",
    "    'InceptionV3': {\n",
    "        'model': InceptionV3,\n",
    "        'preprocess': inceptv3_ppi,\n",
    "        'shape': (299, 299)\n",
    "    },\n",
    "    'MobileNetV2': {\n",
    "        'model': MobileNetV2,\n",
    "        'preprocess': moblv2_ppi,\n",
    "        'shape': (224, 224)\n",
    "    },\n",
    "    'InceptionResNetV2': {\n",
    "        'model': InceptionResNetV2,\n",
    "        'preprocess': inceptres_ppi,\n",
    "        'shape': (299, 299)\n",
    "    },\n",
    "    'Xception': {\n",
    "        'model': Xception,\n",
    "        'preprocess': xcept_ppi,\n",
    "        'shape': (299, 299)\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "class GetCars:\n",
    "    \n",
    "    def __init__(self, loc=\"car_ims/car_ims/\", labels_matlab_file =\"devkit/cars_annos.mat\"):\n",
    "        \n",
    "        self.car_images_location = loc\n",
    "        self.labels_mat = scipy.io.loadmat(labels_matlab_file)\n",
    "        \n",
    "        self.class_names = self.labels_mat['class_names'][0]\n",
    "        \n",
    "        self.max_pics = 16185\n",
    "        \n",
    "        # --- for future\n",
    "        #  Code to check if the 'loc' is a valid dataset\n",
    "        #  if not, download data and unzip\n",
    "        #  same for the labels matlab file\n",
    "        \n",
    "    \n",
    "    def bringAnnot(self, fileName):\n",
    "        if type(fileName) == str:\n",
    "            numb = int(re.sub(r'[^0-9]', '', fileName))\n",
    "        else:\n",
    "            numb = int(fileName)\n",
    "\n",
    "        return ((self.labels_mat['annotations'][0][numb-1]))  \n",
    "    \n",
    "\n",
    "    def bringup_ClassLabel(self, fileName):\n",
    "        if type(fileName) == str:\n",
    "            numb = int(re.sub(r'[^0-9]', '', fileName))\n",
    "        else:\n",
    "            numb = int(fileName)\n",
    "\n",
    "        return self.class_names[int(self.labels_mat['annotations'][0][numb-1][5])-1][0]\n",
    "\n",
    "    \n",
    "    def getPath(self, number):\n",
    "        fileName  = str('0') * int(6 - len(str(number)))\n",
    "        fileName += str(number)+\".jpg\"\n",
    "        return (self.car_images_location + fileName)\n",
    "\n",
    "    \n",
    "    def getImgArray(self, number, target_size=(224, 224) ):\n",
    "        img_path =  self.getPath(number)\n",
    "        img = image.load_img(img_path, target_size=target_size)\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "    def getNextImgArray(self, target_size=(224, 224) ):\n",
    "        count = 0\n",
    "        \n",
    "        while count<self.max_pics:\n",
    "            count += 1        \n",
    "        \n",
    "            yield (count, self.getImgArray(count, target_size))\n",
    "    \n",
    "\n",
    "    def showRandomNxN(self, N):\n",
    "        plt.rcParams['figure.figsize'] = [30, 30]\n",
    "\n",
    "        listofRand = np.random.randint(1, 16185, size=int(N*N))\n",
    "\n",
    "        image_size = (128, 128)\n",
    "\n",
    "        fig = plt.figure()\n",
    "\n",
    "        for i in range(0, N*N):\n",
    "            img = image.load_img(self.getPath(listofRand[i]), target_size=image_size)\n",
    "            ax = fig.add_subplot(N, N, i+1)\n",
    "            imgplot = ax.imshow(img)\n",
    "            ax.set_title(self.bringup_ClassLabel(listofRand[i]))\n",
    "            ax.grid(False)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        plt.show();\n",
    "\n",
    "\n",
    "class GetPretrainedFeatures:\n",
    "    \n",
    "    def __init__(self, cnn=\"VGG16\", database = GetCars(), layer = -1):\n",
    "        \n",
    "        self.cnn = cnn\n",
    "        self.db = database\n",
    "        self.layer_level = layer\n",
    "        \n",
    "    \n",
    "    def get_pretrained_features(self, limit=20, folder = \"\"):\n",
    "        \n",
    "        feature_df = pd.DataFrame()\n",
    "        \n",
    "        model = PRETRAINED_MODELS[self.cnn]['model'](weights='imagenet', include_top=True)\n",
    "        model_layer = Model(inputs=model.input, outputs=model.layers[self.layer_level].output)\n",
    "        preprocess = PRETRAINED_MODELS[self.cnn]['preprocess']\n",
    "        \n",
    "        input_shape = PRETRAINED_MODELS[self.cnn]['shape']\n",
    "        #print(input_shape)\n",
    "        \n",
    "        count = 0\n",
    "        for img in self.db.getNextImgArray(target_size=input_shape):\n",
    "            count += 1\n",
    "            x = preprocess(img[1])\n",
    "            features = model_layer.predict(x)\n",
    "            features = [[img[0]] + list(np.ndarray.flatten(features))]\n",
    "            feature_df = feature_df.append(pd.DataFrame(features), ignore_index=True)\n",
    "            \n",
    "            if count % 1000 == 0:\n",
    "                feature_df.to_csv(folder + self.cnn + \"_\" + str(count//1000) + \".csv\")\n",
    "                print(\"Completed {} pics for {}\".format(count, self.cnn))\n",
    "                feature_df = pd.DataFrame()\n",
    "            \n",
    "            if count == limit:\n",
    "                    break\n",
    "        \n",
    "        if count != limit:\n",
    "            feature_df.to_csv(folder + self.cnn + \"_rest\" + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1000 pics for VGG16\n",
      "Completed 2000 pics for VGG16\n",
      "Completed 3000 pics for VGG16\n",
      "Completed 4000 pics for VGG16\n",
      "Completed 5000 pics for VGG16\n",
      "Completed 6000 pics for VGG16\n",
      "Completed 7000 pics for VGG16\n",
      "Completed 8000 pics for VGG16\n",
      "Completed 9000 pics for VGG16\n",
      "Completed 10000 pics for VGG16\n",
      "Completed 11000 pics for VGG16\n",
      "Completed 12000 pics for VGG16\n",
      "Completed 13000 pics for VGG16\n",
      "Completed 14000 pics for VGG16\n",
      "Completed 15000 pics for VGG16\n",
      "Completed 16000 pics for VGG16\n",
      "Completed 1000 pics for VGG19\n",
      "Completed 2000 pics for VGG19\n",
      "Completed 3000 pics for VGG19\n",
      "Completed 4000 pics for VGG19\n",
      "Completed 5000 pics for VGG19\n",
      "Completed 6000 pics for VGG19\n",
      "Completed 7000 pics for VGG19\n",
      "Completed 8000 pics for VGG19\n",
      "Completed 9000 pics for VGG19\n",
      "Completed 10000 pics for VGG19\n",
      "Completed 11000 pics for VGG19\n",
      "Completed 12000 pics for VGG19\n",
      "Completed 13000 pics for VGG19\n",
      "Completed 14000 pics for VGG19\n",
      "Completed 15000 pics for VGG19\n",
      "Completed 16000 pics for VGG19\n",
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102875136/102869336 [==============================] - 18s 0us/step\n",
      "Completed 1000 pics for ResNet50V2\n",
      "Completed 2000 pics for ResNet50V2\n",
      "Completed 3000 pics for ResNet50V2\n",
      "Completed 4000 pics for ResNet50V2\n",
      "Completed 5000 pics for ResNet50V2\n",
      "Completed 6000 pics for ResNet50V2\n",
      "Completed 7000 pics for ResNet50V2\n",
      "Completed 8000 pics for ResNet50V2\n",
      "Completed 9000 pics for ResNet50V2\n",
      "Completed 10000 pics for ResNet50V2\n",
      "Completed 11000 pics for ResNet50V2\n",
      "Completed 12000 pics for ResNet50V2\n",
      "Completed 13000 pics for ResNet50V2\n",
      "Completed 14000 pics for ResNet50V2\n",
      "Completed 15000 pics for ResNet50V2\n",
      "Completed 16000 pics for ResNet50V2\n",
      "Completed 1000 pics for InceptionV3\n",
      "Completed 2000 pics for InceptionV3\n",
      "Completed 3000 pics for InceptionV3\n",
      "Completed 4000 pics for InceptionV3\n",
      "Completed 5000 pics for InceptionV3\n",
      "Completed 6000 pics for InceptionV3\n",
      "Completed 7000 pics for InceptionV3\n",
      "Completed 8000 pics for InceptionV3\n",
      "Completed 9000 pics for InceptionV3\n",
      "Completed 10000 pics for InceptionV3\n",
      "Completed 11000 pics for InceptionV3\n",
      "Completed 12000 pics for InceptionV3\n",
      "Completed 13000 pics for InceptionV3\n",
      "Completed 14000 pics for InceptionV3\n",
      "Completed 15000 pics for InceptionV3\n",
      "Completed 16000 pics for InceptionV3\n",
      "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n",
      "14540800/14536120 [==============================] - 3s 0us/step\n",
      "Completed 1000 pics for MobileNetV2\n",
      "Completed 2000 pics for MobileNetV2\n",
      "Completed 3000 pics for MobileNetV2\n",
      "Completed 4000 pics for MobileNetV2\n",
      "Completed 5000 pics for MobileNetV2\n",
      "Completed 6000 pics for MobileNetV2\n",
      "Completed 7000 pics for MobileNetV2\n",
      "Completed 8000 pics for MobileNetV2\n",
      "Completed 9000 pics for MobileNetV2\n",
      "Completed 10000 pics for MobileNetV2\n",
      "Completed 11000 pics for MobileNetV2\n",
      "Completed 12000 pics for MobileNetV2\n",
      "Completed 13000 pics for MobileNetV2\n",
      "Completed 14000 pics for MobileNetV2\n",
      "Completed 15000 pics for MobileNetV2\n",
      "Completed 16000 pics for MobileNetV2\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing der .h5-Dateien mit layer = -2 -> hinter dem Softmax-Layer\n",
    "limit_pics = False\n",
    "\n",
    "#vgg16_pre = GetPretrainedFeatures(cnn=\"VGG16\", layer = -2)\n",
    "#vgg16_pre.get_pretrained_features(limit=limit_pics)\n",
    "\n",
    "#vgg19_pre = GetPretrainedFeatures(cnn=\"VGG19\", layer = -2)\n",
    "#vgg19_pre.get_pretrained_features(limit=limit_pics)\n",
    "\n",
    "#res50_pre = GetPretrainedFeatures(cnn=\"ResNet50V2\", layer = -2)\n",
    "#res50_pre.get_pretrained_features(limit=limit_pics)\n",
    "\n",
    "#inception_pre = GetPretrainedFeatures(cnn=\"InceptionV3\", layer = -2)\n",
    "#inception_pre.get_pretrained_features(limit=limit_pics)\n",
    "\n",
    "#mbnet_pre = GetPretrainedFeatures(cnn=\"MobileNetV2\", layer = -2)\n",
    "#mbnet_pre.get_pretrained_features(limit=limit_pics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels.h5\n",
      "91889664/91884032 [==============================] - 52s 1us/step\n",
      "Completed 1000 pics for Xception\n",
      "Completed 2000 pics for Xception\n",
      "Completed 3000 pics for Xception\n",
      "Completed 4000 pics for Xception\n",
      "Completed 5000 pics for Xception\n",
      "Completed 6000 pics for Xception\n",
      "Completed 7000 pics for Xception\n",
      "Completed 8000 pics for Xception\n",
      "Completed 9000 pics for Xception\n",
      "Completed 10000 pics for Xception\n",
      "Completed 11000 pics for Xception\n",
      "Completed 12000 pics for Xception\n",
      "Completed 13000 pics for Xception\n",
      "Completed 14000 pics for Xception\n",
      "Completed 15000 pics for Xception\n",
      "Completed 16000 pics for Xception\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5\n",
      "225214464/225209952 [==============================] - 138s 1us/step\n",
      "Completed 1000 pics for InceptionResNetV2\n",
      "Completed 2000 pics for InceptionResNetV2\n",
      "Completed 3000 pics for InceptionResNetV2\n",
      "Completed 4000 pics for InceptionResNetV2\n",
      "Completed 5000 pics for InceptionResNetV2\n",
      "Completed 6000 pics for InceptionResNetV2\n",
      "Completed 7000 pics for InceptionResNetV2\n",
      "Completed 8000 pics for InceptionResNetV2\n",
      "Completed 9000 pics for InceptionResNetV2\n",
      "Completed 10000 pics for InceptionResNetV2\n",
      "Completed 11000 pics for InceptionResNetV2\n",
      "Completed 12000 pics for InceptionResNetV2\n",
      "Completed 13000 pics for InceptionResNetV2\n",
      "Completed 14000 pics for InceptionResNetV2\n",
      "Completed 15000 pics for InceptionResNetV2\n",
      "Completed 16000 pics for InceptionResNetV2\n"
     ]
    }
   ],
   "source": [
    "limit_pics = False\n",
    "\n",
    "xception_pre = GetPretrainedFeatures(cnn=\"Xception\", layer = -2)\n",
    "xception_pre.get_pretrained_features(limit=limit_pics)\n",
    "\n",
    "incres_pre = GetPretrainedFeatures(cnn=\"InceptionResNetV2\", layer = -2)\n",
    "incres_pre.get_pretrained_features(limit=limit_pics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
